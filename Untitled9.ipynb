{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvSHD/2RzJ10kfRhI4Qbei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedelzaim77/C-Users-moham-Contacts/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDkvQOCmUAc-",
        "outputId": "05f0c1b5-5a0c-4bbe-c48a-612d2133461f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 1.3864\n",
            "Epoch 200: Loss = 0.0071\n",
            "Epoch 400: Loss = 0.0028\n",
            "Epoch 600: Loss = 0.0017\n",
            "Epoch 800: Loss = 0.0012\n",
            "Epoch 1000: Loss = 0.0010\n",
            "Epoch 1199: Loss = 0.0008\n",
            "\n",
            "\n",
            "Given sequence: ['i', 'love', 'real']\n",
            "Predicted next word: Madrid\n",
            "Output probabilities: \n",
            "  i      : 0.0002\n",
            "  love   : 0.0004\n",
            "  real   : 0.0001\n",
            "  Madrid : 0.9993\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "words = ['i', 'love', 'real', 'Madrid']\n",
        "word_to_idx = {w: i for i, w in enumerate(words)}\n",
        "idx_to_word = {i: w for i, w in enumerate(words)}\n",
        "vocab_size = len(words)\n",
        "\n",
        "X_seq = ['i', 'love', 'real']\n",
        "Y_seq = ['love', 'real', 'Madrid']\n",
        "\n",
        "def one_hot(idx, size):\n",
        "    v = np.zeros(size)\n",
        "    v[idx] = 1\n",
        "    return v\n",
        "\n",
        "X = np.array([one_hot(word_to_idx[w], vocab_size) for w in X_seq])\n",
        "Y = np.array([one_hot(word_to_idx[w], vocab_size) for w in Y_seq])\n",
        "\n",
        "np.random.seed(42)\n",
        "hidden_size = 8\n",
        "\n",
        "U = np.random.randn(hidden_size, vocab_size) * 0.01\n",
        "W = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "V = np.random.randn(vocab_size, hidden_size) * 0.01\n",
        "\n",
        "b = np.zeros((hidden_size, 1))\n",
        "c = np.zeros((vocab_size, 1))\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / np.sum(e_x, axis=0, keepdims=True)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def dtanh(x):\n",
        "    return 1.0 - np.tanh(x) ** 2\n",
        "\n",
        "\n",
        "def forward(X):\n",
        "    h = {}\n",
        "    y_hat = {}\n",
        "    h[-1] = np.zeros((hidden_size, 1))\n",
        "    for t in range(len(X)):\n",
        "        x_t = X[t].reshape(-1, 1)\n",
        "        h[t] = tanh(np.dot(U, x_t) + np.dot(W, h[t-1]) + b)\n",
        "        y_hat[t] = softmax(np.dot(V, h[t]) + c)\n",
        "    return h, y_hat\n",
        "\n",
        "def calculate_loss(Y, y_hat):\n",
        "    loss = 0\n",
        "    for t in range(len(Y)):\n",
        "                loss -= np.sum(Y[t].reshape(-1,1) * np.log(y_hat[t] + 1e-8))\n",
        "    return loss / len(Y)\n",
        "\n",
        "def backward(X, Y, h, y_hat):\n",
        "    dU = np.zeros_like(U)\n",
        "    dW = np.zeros_like(W)\n",
        "    dV = np.zeros_like(V)\n",
        "    db = np.zeros_like(b)\n",
        "    dc = np.zeros_like(c)\n",
        "    dh_next = np.zeros_like(h[0])\n",
        "\n",
        "    for t in reversed(range(len(X))):\n",
        "        dy = y_hat[t] - Y[t].reshape(-1,1)\n",
        "        dV += np.dot(dy, h[t].T)\n",
        "        dc += dy\n",
        "        dh = np.dot(V.T, dy) + dh_next\n",
        "        dh_raw = dh * dtanh(np.dot(U, X[t].reshape(-1,1)) + np.dot(W, h[t-1]) + b)\n",
        "        db += dh_raw\n",
        "        dU += np.dot(dh_raw, X[t].reshape(1, -1))\n",
        "        dW += np.dot(dh_raw, h[t-1].T)\n",
        "        dh_next = np.dot(W.T, dh_raw)\n",
        "    for dparam in [dU, dW, dV, db, dc]:\n",
        "        np.clip(dparam, -5, 5, out=dparam)\n",
        "    return dU, dW, dV, db, dc\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 1200\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    h, y_hat = forward(X)\n",
        "    loss = calculate_loss(Y, y_hat)\n",
        "    dU, dW, dV, db, dc = backward(X, Y, h, y_hat)\n",
        "    U -= learning_rate * dU\n",
        "    W -= learning_rate * dW\n",
        "    V -= learning_rate * dV\n",
        "    b -= learning_rate * db\n",
        "    c -= learning_rate * dc\n",
        "    if epoch % 200 == 0 or epoch == epochs-1:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "def predict_next_word(input_words):\n",
        "    x_seq = [one_hot(word_to_idx[w], vocab_size) for w in input_words]\n",
        "    h_last = np.zeros((hidden_size, 1))\n",
        "    for t in range(len(x_seq)):\n",
        "        h_last = tanh(np.dot(U, x_seq[t].reshape(-1,1)) + np.dot(W, h_last) + b)\n",
        "    y_pred = softmax(np.dot(V, h_last) + c)\n",
        "    pred_word_idx = np.argmax(y_pred)\n",
        "    return idx_to_word[pred_word_idx], y_pred\n",
        "\n",
        "context = ['i','love','real']\n",
        "predicted_word, prob = predict_next_word(context)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Given sequence: {context}\")\n",
        "print(f\"Predicted next word: {predicted_word}\")\n",
        "print(f\"Output probabilities: \")\n",
        "for i, w in idx_to_word.items():\n",
        "    print(f\"  {w:7}: {prob[i,0]:.4f}\")\n"
      ]
    }
  ]
}